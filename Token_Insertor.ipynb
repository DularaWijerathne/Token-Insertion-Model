{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d21d4ff3-0fe2-4b04-b162-acf4c2b5da29",
   "metadata": {},
   "source": [
    "# User Guid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8df163-d23e-4ac5-a119-9597f46dce74",
   "metadata": {},
   "source": [
    "STEP 1: Run all the cells below.\n",
    "\r\n",
    "STEP 2: Define your text (paragraph)thate you want to insert the token <'X'>\n",
    "\n",
    "\r\n",
    "STEP 3: Run the function \"predict(text)\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baadc028-e500-4d61-9a86-699d5a3db61a",
   "metadata": {},
   "source": [
    "#### Example:\n",
    "\n",
    "input : \"In the second step of the IFM procedure, we made use of the Expectation--Maximisation algorithm of in order to deal with the markovian structure characterising the latent states. Further details about the employed estimation technique can be found in.\"\n",
    "\n",
    "output : \"in the second step of the ifm procedure, we made use of the expectation - - maximisation algorithm of <'x'> in order to deal with the markovian structure characterising the latent states. further details about the employed estimation technique can be found in <'x'>.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "671085e7-2139-4f8d-b857-a4193553e37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c5f1c24-097b-4f52-984e-481bab811581",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "     tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9d0f513-c1dd-472a-ac8e-7c0df24ae47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a180c258-2037-4286-a8cc-4292f04d27b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define F1 score metric\n",
    "\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = Precision()\n",
    "        self.recall = Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred)\n",
    "        self.recall.update_state(y_true, y_pred)\n",
    "\n",
    "    def result(self):\n",
    "        precision_result = self.precision.result()\n",
    "        recall_result = self.recall.result()\n",
    "        return 2 * ((precision_result * recall_result) / (precision_result + recall_result + tf.keras.backend.epsilon()))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.precision.reset_state()\n",
    "        self.recall.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "561cb721-a6a4-4252-83ff-d73cd1e0cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_paragraph(paragraph):\n",
    "    sentences_list = []\n",
    "    split_list = paragraph.split('. ')\n",
    "    for sentence in split_list:\n",
    "        if sentence[-1]=='.':\n",
    "            sentences_list.append(sentence)\n",
    "        else:\n",
    "            sentences_list.append(sentence+'.')\n",
    "    return sentences_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1270d7d3-9650-4efc-9196-1b0b626553eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_spaces(sentence):\n",
    "    cleaned_sentence = sentence.replace(\"( \", \"(\").replace(\" )\", \")\").replace(\" -\", \"-\").replace(\"- \", \"-\").replace(\" !\", \"!\").replace(\" :\", \":\")\n",
    "    return cleaned_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e4851df2-8442-4e60-8fab-2a25d1332431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sentence(org_sentence, sentence):\n",
    "    tags = org_sentence[:-1].split(' ')\n",
    "    X_indexes = []\n",
    "    for index, word in enumerate(sentence[:-1].split(' ')):\n",
    "        if \"<x>\" == word:\n",
    "            tags.insert(index, \"<X>\")\n",
    "        elif \"<x>,\" == word:\n",
    "            tags[index-1] = tags[index-1][:-1]\n",
    "            tags.insert(index, \"<X>,\")\n",
    "        elif \"<x>:\" == word:\n",
    "            tags[index-1] = tags[index-1][:-1]\n",
    "            tags.insert(index, \"<X>:\")\n",
    "\n",
    "    return \" \".join(tags)+'.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "573d696b-04af-48da-a3c0-7fd8b0b7573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use for inserting token <X> into your text\n",
    "\n",
    "def predict (text, threshold=0.5, max_len=60):\n",
    "    model = tf.keras.models.load_model(model_dir + 'model/token_insertion_model.h5', \n",
    "                                   custom_objects={'TFBertModel': TFBertModel, 'F1Score': F1Score, 'Precision': Precision, 'Recall': Recall}) \n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    tokenizer.add_tokens(\"<X>\")\n",
    "\n",
    "    sentences_with_mask = []\n",
    "    sentences_list = break_paragraph(text)\n",
    "\n",
    "    for sentence in sentences_list:\n",
    "        input_dict = tokenizer(sentence, max_length=max_len, padding='max_length', truncation=True, return_tensors=\"tf\")\n",
    "        input_ids = input_dict['input_ids']\n",
    "        attention_mask = input_dict['attention_mask']\n",
    "        insertion_points = []\n",
    "        \n",
    "        prediction = model.predict([input_ids, attention_mask])\n",
    "    \n",
    "        binary_predictions = [1 if pred > threshold else 0 for pred in prediction[0]]\n",
    "        \n",
    "        for i, pred in enumerate(binary_predictions):\n",
    "            if pred == 1:\n",
    "                insertion_points.append(i+1)\n",
    "\n",
    "        ids_with_mask = np.insert(input_ids, insertion_points, tokenizer.encode(\"<X>\", add_special_tokens=False))\n",
    "        decoded_sentence = tokenizer.decode(ids_with_mask, skip_special_tokens=True)\n",
    "        cleaned_sentence = clean_spaces(decoded_sentence)\n",
    "        formatted_sentence = format_sentence(sentence, cleaned_sentence)\n",
    "        sentences_with_mask.append(formatted_sentence)\n",
    "        \n",
    "    output = \" \".join(sentences_with_mask)\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6befad6-0821-4cb4-8797-f9f54caa415b",
   "metadata": {},
   "source": [
    "## Change the \"text\" as you need and run the function \"predict(text)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "461ea961-8cfe-4e4e-ba56-7e4c93ee038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = '''In the second step of the IFM procedure, we made use of the Expectation--Maximisation algorithm of in order to deal with the markovian \n",
    "structure characterising the latent states. Further details about the employed estimation technique can be found in.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1a771c4e-766d-43cc-89bd-dad8a52fe846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "In the second step of the IFM procedure, we made use of the Expectation--Maximisation algorithm of <X> in order to deal with the markovian \n",
      "structure characterising the latent states. Further details about the employed estimation technique can be found in <X>.\n"
     ]
    }
   ],
   "source": [
    "print(predict(text_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5c79aada-ec59-47de-ab31-9fdd3e8b5d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_2 = 'It is also worth noticing that the results in give the Hausdorff dimension of.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "65706039-0437-45b2-8162-cdf8ee8e3704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "It is also worth noticing that the results in <X> give the Hausdorff dimension of.\n"
     ]
    }
   ],
   "source": [
    "print(predict(text_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "03e62ce2-d8f7-4da3-9a9a-a001e9484f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_3 = '''While convolutional neural networks have resulted in many practical successes, they can be highly susceptible to adversarial examples. \n",
    "In one extreme case, the change of a single pixel within the input image can with high confidence change the output prediction of the network'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c45c1d85-b9df-4c97-a54c-bb4c06cfa93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "While convolutional neural networks have resulted in many practical successes <X>, they can be highly susceptible to adversarial examples. \n",
      "In one extreme case, the change of a single pixel within the input image can with high confidence change the output prediction of the network <X>.\n"
     ]
    }
   ],
   "source": [
    "print(predict(text_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2e193d13-3da7-4804-a165-9d7fa6b8a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_4 = '''We now discuss the junction conditions needed for the numerical integration of the oscillations' equations when a sharp \n",
    "interface due to a first order phase transition takes place inside a hybrid compact star. Such conditions are intrinsically related \n",
    "to the velocity of the phase transition near the surface splitting any two phases (see for further details).'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0604dc82-8e8e-48f0-b626-4c4ced8c8873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "We now discuss the junction conditions needed for the numerical integration of the oscillations' equations when a sharp \n",
      "interface due to a first order phase transition takes place inside a hybrid compact <X> star. Such conditions are intrinsically related \n",
      "to the velocity of the phase transition near the surface splitting any two phases (see <X> for further details).\n"
     ]
    }
   ],
   "source": [
    "print(predict(text_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ab12198c-a05c-4e29-a5ce-59233b5797c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_5 = '''We evaluate CODEFUSION on NL-to-code for three different languages: Python, Bash, and conditional formatting rules in Microsoft Excel. \n",
    "Our results show that CODEFUSION's (75M parameters) top-1 results are comparable or better than much larger state-of-the-art systems \n",
    "(350M-175B parameters). In top-3 and top-5, CODEFUSION performs better than all baselines.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ac6f90e5-52e4-4f57-b627-c4b0b0fd16af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "We evaluate CODEFUSION on NL-to-code for three different languages: Python <X>, Bash <X>, and conditional formatting rules in Microsoft Excel <X>. \n",
      "Our results show that CODEFUSION's (75M parameters) top-1 results are comparable or better than much larger state-of-the-art systems <X> \n",
      "(350M-175B parameters). In top-3 and top-5, CODEFUSION <X> performs better than all baselines.\n"
     ]
    }
   ],
   "source": [
    "print(predict(text_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090e8608-128e-4519-a4ac-97f8f9e4ed3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
